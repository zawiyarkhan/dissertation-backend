{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c494c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84e41a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import wave\n",
    "import json\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk import FreqDist\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c3d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5p/j0ltycyj5b19sy6yyqzr7q500000gn/T/ipykernel_99627/222396416.py:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(\"5 Britten Close.m4a\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean pitch (Hz): 320.13388\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y, sr = librosa.load(\"5 Britten Close.m4a\")\n",
    "# Use librosa's piptrack for pitch tracking\n",
    "pitches, magnitudes = librosa.piptrack(y=y, sr=sr)\n",
    "\n",
    "# Extract the strongest pitch per frame\n",
    "pitch_values = []\n",
    "for i in range(pitches.shape[1]):\n",
    "    index = magnitudes[:, i].argmax()\n",
    "    pitch = pitches[index, i]\n",
    "    if pitch > 0:  # Remove zero or negative values\n",
    "        pitch_values.append(pitch)\n",
    "\n",
    "pitch_values = np.array(pitch_values)\n",
    "print(\"Mean pitch (Hz):\", np.mean(pitch_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bed4b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Jitter (local): 0.34649768\n"
     ]
    }
   ],
   "source": [
    "# Estimate jitter (approximate)\n",
    "if len(pitch_values) > 1:\n",
    "    diffs = np.abs(np.diff(pitch_values))\n",
    "    jitter_local = np.mean(diffs / pitch_values[:-1])\n",
    "    print(\"Approximate Jitter (local):\", jitter_local)\n",
    "else:\n",
    "    print(\"Insufficient pitch data for jitter estimation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d6a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Shimmer (local): 0.20525113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute short-time RMS energy\n",
    "rms = librosa.feature.rms(y=y)[0]\n",
    "\n",
    "# Estimate shimmer as the mean absolute percentage difference between frames\n",
    "if len(rms) > 1:\n",
    "    shimmer_values = np.abs(np.diff(rms)) / rms[:-1]\n",
    "    shimmer_local = np.mean(shimmer_values)\n",
    "    print(\"Approximate Shimmer (local):\", shimmer_local)\n",
    "else:\n",
    "    print(\"Insufficient RMS data for shimmer estimation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bff31e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech Duration: 8.661043083900225\n",
      "Speech Rate (ratio): 0.7463819376321476\n"
     ]
    }
   ],
   "source": [
    "# 4. Speech rate and pauses\n",
    "intervals = librosa.effects.split(y, top_db=20)\n",
    "speech_durations = sum([(end - start) / sr for start, end in intervals])\n",
    "total_duration = len(y) / sr\n",
    "speech_ratio = speech_durations / total_duration\n",
    "print(\"Speech Duration:\", speech_durations)\n",
    "print(\"Speech Rate (ratio):\", speech_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af5bfe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Convert M4A to WAV\n",
    "input_audio_path = \"5 Britten Close.m4a\"\n",
    "AUDIO_PATH = \"converted.wav\"\n",
    "\n",
    "if not os.path.exists(AUDIO_PATH):\n",
    "    audio = AudioSegment.from_file(input_audio_path, format=\"m4a\")\n",
    "    audio.export(AUDIO_PATH, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31fabcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='converted.wav'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "input_path = \"5 Britten Close.m4a\"\n",
    "output_path = \"converted.wav\"\n",
    "\n",
    "sound = AudioSegment.from_file(input_path)\n",
    "sound = sound.set_channels(1)\n",
    "sound = sound.set_frame_rate(16000)\n",
    "sound.export(output_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90326ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=10 max-active=3000 lattice-beam=2\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from model/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:282) Loading HCL and G from model/graph/HCLr.fst model/graph/Gr.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo model/graph/phones/word_boundary.int\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Final Transcript:\n",
      " the hello my name is my name is or where clinton plan plan and this is our dog this is for testing testing testing\n",
      "Average Sentence Length: 24.0\n",
      "Vocabulary Richness: 0.625\n",
      "Top Words: [('is', 4), ('testing', 3), ('my', 2), ('name', 2), ('plan', 2), ('this', 2), ('the', 1), ('hello', 1), ('or', 1), ('where', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wf = wave.open(AUDIO_PATH, \"rb\")\n",
    "vosk_model_path = \"model\"  # VOSK model directory (download from https://alphacephei.com/vosk/models)\n",
    "if not os.path.exists(vosk_model_path):\n",
    "    print(\"Please download and extract VOSK model to 'model/' folder.\")\n",
    "model = Model(vosk_model_path)\n",
    "rec = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "results = []\n",
    "\n",
    "while True:\n",
    "    data = wf.readframes(8000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "\n",
    "    if rec.AcceptWaveform(data):\n",
    "        result = json.loads(rec.Result())\n",
    "        print(\"‚úÖ Full:\", result)\n",
    "        results.append(result.get(\"text\", \"\"))\n",
    "    else:\n",
    "        partial = json.loads(rec.PartialResult())\n",
    "        # print(\"üü° Partial:\", partial)\n",
    "\n",
    "# Final catch\n",
    "final_result = json.loads(rec.FinalResult())\n",
    "results.append(final_result.get(\"text\", \"\"))\n",
    "\n",
    "transcript = \" \".join(results)\n",
    "print(\"\\nüìù Final Transcript:\\n\", transcript)\n",
    "\n",
    "\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download('punkt')\n",
    "words = word_tokenize(transcript)\n",
    "sentences = sent_tokenize(transcript)\n",
    "avg_sentence_length = np.mean([len(word_tokenize(s)) for s in sentences])\n",
    "vocab_richness = len(set(words)) / len(words)\n",
    "word_freq = FreqDist(words).most_common(10)\n",
    "print(\"Average Sentence Length:\", avg_sentence_length)\n",
    "print(\"Vocabulary Richness:\", vocab_richness)\n",
    "print(\"Top Words:\", word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6541c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
