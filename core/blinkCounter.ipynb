{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bcd73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "from cvzone.PlotModule import LivePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545ecc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750775164.958218 4764839 gl_context.cc:369] GL version: 2.1 (2.1 INTEL-23.0.26), renderer: Intel(R) Iris(TM) Plus Graphics 645\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1750775164.967575 4764969 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('test1.mp4.mov')\n",
    "detector = FaceMeshDetector(maxFaces=1)\n",
    "plotY = LivePlot(640, 360, [20, 50], invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idList = [22, 23, 24, 26, 110, 157, 158, 159, 160, 161, 130, 243]\n",
    "ratioList = []\n",
    "blinkCounter = 0\n",
    "counter = 0\n",
    "color = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bda060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1750775165.000943 4764963 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1750775165.061140 4764965 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m#     cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\u001b[39;00m\n\u001b[32m      6\u001b[39m     success, img = cap.read()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     img, faces = \u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindFaceMesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m faces:\n\u001b[32m     10\u001b[39m         face = faces[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/cvzone/FaceMeshModule.py:45\u001b[39m, in \u001b[36mFaceMeshDetector.findFaceMesh\u001b[39m\u001b[34m(self, img, draw)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfindFaceMesh\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, draw=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     39\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    Finds face landmarks in BGR Image.\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    :param img: Image to find the face landmarks in.\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    :param draw: Flag to draw the output on the image.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m    :return: Image with or without drawings\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgRGB = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m.results = \u001b[38;5;28mself\u001b[39m.faceMesh.process(\u001b[38;5;28mself\u001b[39m.imgRGB)\n\u001b[32m     47\u001b[39m     faces = []\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    # if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "    #     cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    success, img = cap.read()\n",
    "    img, faces = detector.findFaceMesh(img, draw=False)\n",
    "\n",
    "    if faces:\n",
    "        face = faces[0]\n",
    "        for id in idList:\n",
    "            cv2.circle(img, face[id], 5,color, cv2.FILLED)\n",
    "\n",
    "        leftUp = face[159]\n",
    "        leftDown = face[23]\n",
    "        leftLeft = face[130]\n",
    "        leftRight = face[243]\n",
    "        lenghtVer, _ = detector.findDistance(leftUp, leftDown)\n",
    "        lenghtHor, _ = detector.findDistance(leftLeft, leftRight)\n",
    "\n",
    "        cv2.line(img, leftUp, leftDown, (0, 200, 0), 3)\n",
    "        cv2.line(img, leftLeft, leftRight, (0, 200, 0), 3)\n",
    "\n",
    "        ratio = int((lenghtVer / lenghtHor) * 100)\n",
    "        ratioList.append(ratio)\n",
    "        if len(ratioList) > 3:\n",
    "            ratioList.pop(0)\n",
    "        ratioAvg = sum(ratioList) / len(ratioList)\n",
    "\n",
    "        if ratioAvg < 37 and counter == 0:\n",
    "            blinkCounter += 1\n",
    "            color = (0,200,0)\n",
    "            counter = 1\n",
    "        if counter != 0:\n",
    "            counter += 1\n",
    "            if counter > 10:\n",
    "                counter = 0\n",
    "                color = (255,0, 255)\n",
    "\n",
    "        cvzone.putTextRect(img, f'Blink Count: {blinkCounter}', (50, 100),\n",
    "                           colorR=color)\n",
    "\n",
    "        imgPlot = plotY.update(ratioAvg, color)\n",
    "        img = cv2.resize(img, (640, 360))\n",
    "        imgStack = cvzone.stackImages([img, imgPlot], 2, 1)\n",
    "    else:\n",
    "        img = cv2.resize(img, (640, 360))\n",
    "        imgStack = cvzone.stackImages([img, img], 2, 1)\n",
    "\n",
    "    cv2.imshow(\"Image\", imgStack)\n",
    "    cv2.waitKey(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ef801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
